--IDEAS--
-------------------------------------------------
(1) Find websides which stores information about Finnish startups, especially with recent fundings and news about expansion
    -> startup100
    -> crunchbase
    (-> healthtech finland (but they only provide web page links))
    (-> wellfound.com, its more like a job listing)
    -> failory (it's not a database but has some insights) (failory/startups/finland)
    -> f6s (f6s/companies/finland/lo)

(2) Build scrapers for each website, retrieving necessary data, and store in csv files
    - name
    - founding year
    - summary description
    - total fundings
    - recent funding
    - website link
    - carrer page
    (- news)
        ----> use classes for scalabilitie etc.

(3) Organize files and summarize everything in a final csv file

((4) Organize data in database and other data files (like json) (sqllite))

-------------------------------------------------
--OTHER IDEAS--
-------------------------------------------------
- add bash scripts for automatition and other useful functionality
- write unit tests (and automize it)
- for dynamic websites with interactive features, use Selenium or Playwright
- add proxy rotation on websites with robot.txt files and handle authentication
- store data in database
(- add multithreading to do asynchronous scraping)
- deploy to cloud (like AWS)
- http request?
- use Docker
- implement LLM functionality (e.g. Notion uses AI to search the workplace for asked material)

-------------------------------------------------
--TO-DO--
-------------------------------------------------
- error handling
- change hardcoded file-creation and management
- add logging file to document process and errors with timestamps [DONE]
    -> transfer all alerts to log function
- build classes -> (WebScraper, Parser, Logging, DataBase, etc.)
- consider encapsulation -> what instances are going to be private, etc.
- write cron job bash script to automate scraper
- write tests

-------------------------------------------------
--UPDATES--
-------------------------------------------------
24.09.2024 simple scraper for 'startup100' made -> get info of table on starting page and saves in csv-file, unprocessed
28.09.2024 init class for first webscraper -> will be parent for other child scraper classes
!!! 28.09.2024 parsing does not work as intended -> FIX NEEDED
05.10.2024 FIX: parser fixed
05.10.2024 MODIFICATION: data stored in a dict
13.10.2024 MODIFICATION: new data gets appended in file, duplicates are removed 
--- 13.10.2024 stored data still looks ugly ---
19.10.2024 FEATURE: Log added
!!! 19.10.2024 logging creates duplicates !!!
!!! 19.10.2024 some loggig of error handling is not sufficient e.g. when File error, it still prints 'data stored successfully' !!!
!!! 19.10.2024 tests are not working -> can't find modules (storage, parser, etc.) !!!